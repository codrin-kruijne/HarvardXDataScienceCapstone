---
title: "Movie recommendation results"
output:
  pdf_document: default
  html_notebook: default
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(cache = TRUE)
script_start <- Sys.time()
```

# Loading packages and data

The [dataset](http://files.grouplens.org/datasets/movielens/ml-10m.zip) was downloaded from the [GroupLens website](https://grouplens.org) using the course provided script and stored locally. Information about the data was found on the [MovieLens README] (http://files.grouplens.org/datasets/movielens/ml-10m-README.html)

```{r}
# Load required packages
library(tidyverse)
library(lubridate)

# Load locally stored data
edx_original <- readRDS("edx.RData")
print(str(edx_original))
validation_original <- readRDS("validation.RData")
print(str(validation_original))

# Make sure movies and users are in both train and test sets ### USERS DIFFER
train_data <- edx_original
print(str(train_data))
test_data <- validation_original %>% 
     semi_join(train_data, by = "movieId") %>%
     semi_join(train_data, by = "userId")
print(str(test_data))

all_data <- setNames(list(train_data, test_data), c("train_data", "test_data"))
```

# Preparing data

```{r include = FALSE}

# Let's prepare parallel processing
library(parallel)
no_cores <- detectCores() - 2
pcl <- makeCluster(no_cores)
clusterEvalQ(pcl, library(dplyr))
clusterEvalQ(pcl, library(lubridate))
clusterEvalQ(pcl, library(stringr))

```

```{r}

# Some basic data transformation is done to both training and test data

# Separating user characteristics, ratings and movie features
extract_user_data <- function(original_data){
  original_data %>% select(userId) %>%
                    mutate(userId = as.factor(userId)) %>% unique()
}

# Separating and transforming rating data
extract_rating_data <- function(original_data){
  original_data %>% select(userId, movieId, rating, timestamp) %>%
                    mutate(userId = as.factor(userId),
                           movieId = as.factor(movieId),
                           date = as.POSIXct(timestamp, origin = "1970-01-01")) %>% # Turn rating timestamps to date
                           mutate(rating_year = year(date)) %>%
                    select(-timestamp, -date)
}

# Separating and transforming movie data
extract_movie_data <- function(original_data){

  # Let's determine which genres we have
  unique_genres <- unique(str_extract(original_data$genres, "[^\\|]+"))

  movie_data <- original_data %>% select(movieId, title, genres) %>%
                                  unique() %>%
                                  mutate(movieId = as.factor(movieId),
                                         movie_year = as.factor(str_sub(title, -5, -2)),
                                         title = str_sub(title, 0, -8))
  
  
  # Now lets add genres as columns
  movie_data[, unique_genres] <- NA
  
  # For each of the ratings we detect present genres
  for(g in 1:length(unique_genres)) {
    movie_data[, unique_genres[g]] <- str_detect(movie_data$genres, unique_genres[g])
  }
  # Drop old columns
  movie_data <- movie_data %>% select(-genres)
  
}

# Apply all data transformations in parallel
user_data <- parLapply(pcl, all_data, extract_user_data)
rating_data <- parLapply(pcl, all_data, extract_rating_data)
movie_data <- parLapply(pcl, all_data, extract_movie_data)

# Let's explore our new data sets
str(user_data)
str(rating_data)
str(movie_data) ### NO GENRES LISTED
```

# Calculating statistics

```{r}
## User statistics
calc_user_stats <- function(rating_data){
  
  rating_data %>% group_by(userId) %>%
                  summarise(user_ratings = n(),
                            user_median = median(rating),
                            user_mean = mean(rating),
                            user_sd = sd(rating)) %>%
                  select(userId, user_median, user_mean, user_sd) %>%
                  unique()

}

user_stats <- parLapply(pcl, rating_data, calc_user_stats)

# Movie rating statistics
calc_movie_stats <- function(rating_data){
  
  rating_data %>% group_by(movieId) %>%
                  summarise(movie_ratings = n(),
                            movie_median = median(rating),
                            movie_mean = mean(rating),
                            movie_sd = sd(rating)) %>%
                  select(movieId, movie_median, movie_mean, movie_sd) %>%
                  unique()
  
} 

movie_stats <- parLapply(pcl, rating_data, calc_movie_stats)

# Merge statistics back
merge_data <- list(list(rating_data[[1]], user_stats[[1]], movie_stats[[1]]), # train data
                   list(rating_data[[2]], user_stats[[2]], movie_stats[[2]])) # test data

merge_stats <- function(data_stats){
  
  rating_data <- data_stats[[1]]
  user_stats <- data_stats[[2]]
  movie_stats <- data_stats[[3]]
    
  rating_data %>% inner_join(user_stats, by = "userId") %>%
                  inner_join(movie_stats, by = "movieId")

}

rating_data <- parLapply(pcl, merge_data, merge_stats)

## Rating characteristics
calc_rating_stats <- function(rating_data){
  rating_mean <- mean(rating_data$rating)

  rating_data <- rating_data %>% mutate(rating_mean_diff = rating - rating_mean) %>% 
                                 mutate(movie_mean_diff = rating - movie_mean) %>% 
                                 mutate(user_mean_diff = rating - user_mean)
  
}

rating_data <- parLapply(pcl, rating_data, calc_rating_stats)

```

# Derived models
```{r}

train_ratings <- rating_data[[1]]
test_ratings <- rating_data[[2]]

# RSME loss function function to evaluate models
RMSE <- function(predicted_ratings, true_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}

# Deried models

# Naive model using average rating
train_mean <- mean(train_ratings$rating)
train_mean

naive_rmse <- RMSE(test_ratings$rating, train_mean)

derived_results <- tibble(method = "Average training rating", RMSE = naive_rmse)

# Model using fixed number
fixed_number <- rep(2.5, nrow(test_ratings))

fixed_rmse <- RMSE(test_ratings$rating, fixed_number)

derived_results <- bind_rows(derived_results,
                             tibble(method = "Fixed number 2.5",
                                    RMSE = fixed_rmse ))

# Derived predictions

movie_pred <- test_ratings %>% group_by(movieId) %>%
               # Rating effect (effect of rating scale used; looking at differences from rating mean)      
                               summarise(rating_mean_diff_avg = train_mean + mean(rating_mean_diff),
               # Movie effect (effect of general movie popularity; looking at differences between user rating and movie mean)
                                         movie_mean_diff_avg = train_mean + mean(movie_mean_diff),
               # User effect (effect of user rating behaviour; looking at differeces between rating and average user rating)
                                         user_mean_diff_avg = train_mean + mean(user_mean_diff),
               # User-movie effect (effect of user rating behaviour; looking at differeces between user rating and average movie rating)
                                         user_movie_mean_diff_avg = train_mean + mean(mean(movie_mean_diff), mean(user_mean_diff)))

der_pred <- test_ratings %>% inner_join(movie_pred, by = "movieId")

# Calculate RMSEs
rating_effect_rmse <- RMSE(test_ratings$rating,
                           der_pred$rating_mean_diff_avg)
movie_mean_rmse <- RMSE(test_ratings$rating,
                        test_ratings$movie_mean)
movie_effect_rmse <- RMSE(test_ratings$rating,
                          der_pred$movie_mean_diff_avg)
user_effect_rmse <- RMSE(test_ratings$rating,
                         der_pred$user_mean_diff_avg)
user_movie_effect_rmse <- RMSE(test_ratings$rating,
                               der_pred$user_movie_mean_diff_avg)

# Print RMSEs

derived_results <- bind_rows(derived_results,
                             tibble(method = "Rating effect",
                                    RMSE = rating_effect_rmse))
derived_results <- bind_rows(derived_results,
                             tibbel(method = "Movie mean",
                                    RMSE = movie_mean_rmse))
derived_results <- bind_rows(derived_results,
                             tibble(method = "Movie effect",
                                    RMSE = movie_effect_rmse))
derived_results <- bind_rows(derived_results,
                             tibble(method = "User effect",
                                    RMSE = user_effect_rmse))
derived_results <- bind_rows(derived_results,
                             tibble(method = "User-movie effect",
                                    RMSE = user_movie_effect_rmse))

saveRDS(derived_results, "derived_results.RData")
print(derived_results)

stopCluster(pcl)

```


# Train linear models
```{r}
# Free up memory
rm(edx_original,
   validation_original,
   train_data,
   test_data,
   all_data,
   user_data,
   movie_data,
   rating_data,
   merge_data,
   der_pred)
gc() # garbage collection

library(caret)

# Set up parallel processing
library(doParallel)
no_cores <- detectCores() - 2
tcl <- makePSOCKcluster(no_cores)
registerDoParallel(tcl)
print(paste("Memory size before garbage collection: ", memory.size()))
gc()
print(paste("Memory size after garbage collection: ", memory.size()))

## Define models
model_formulas <- c("rating ~ movie_median",
                    "rating ~ movie_median + movie_mean",
                    "rating ~ movie_median + movie_mean + movie_sd",
                    "rating ~ user_median",
                    "rating ~ user_median + user_mean",
                    "rating ~ user_median + user_mean + user_sd",
                    # Let's combine movie and user characteristics
                    "rating ~ movie_mean + user_mean",
                    "rating ~ movie_median + user_median",
                    "rating ~ movie_median + movie_mean + user_median + user_mean",
                    
                    "rating ~ movie_median + movie_mean + movie_sd + user_median + user_mean + user_sd")

## Model training

e <- simpleError("Catch error")

train_lm <- function(lm_formula, lm_data){
  
  print(paste("Model formula: ", lm_formula))
  
  print(system.time({
    model <- tryCatch({
               train(as.formula(lm_formula),
                     data = lm_data, method = "lm", 
                     na.action = na.omit) 
             }, error = function(e) e, finally = print("Made it!"))
  }))
  
  # How's our memory?
  print(paste("Memory size before garbage collection: ", memory.size()))
  gc()
  print(paste("Memory size after garbage collection: ", memory.size()))
  
  # Return results
  print(model$finalModel)
  model
}

# Alternatively try(train_lm)
model_fits <- lapply(model_formulas, train_lm, lm_data = train_ratings)

# Stop parallel processing
stopCluster(tcl)

# Save locally
saveRDS(model_fits, "model_fits.RData")
  
```

# Model prediction and results
```{r}
# Read stored models
# model_fits <- readRDS("model_fits.RData")

rcl <- makeCluster(no_cores)
clusterEvalQ(rcl, library(dplyr))

# Predict on test_set
system.time({
  model_predictions <- parLapply(rcl, model_fits, try(predict), newdata = test_ratings)  
})

# Print results on test set

model_results <- parLapply(rcl, model_predictions, RMSE, true_ratings = test_ratings$rating)

lm_results <- data.frame(model = model_formulas, rmse = unlist(model_results))

saveRDS(lm_results, "lm_results.RData")
print(lm_results %>% arrange(rmse))

stopCluster(rcl)

rm(model_fits) # Remove models to free up memory
gc() # Garbage collection

```

```{r}

# Shall we explore auto ML?

library(h2o)

h2o.init()

# Import a sample binary outcome train/test set into H2O
train <- as.h2o(train_ratings)
test <- as.h2o(test_ratings)

# Identify predictors and response
y <- "rating"
x <- setdiff(names(train), y)

# Run AutoML for 10 base models (limited to 1 hour max runtime by default)
aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  validation_frame = test,
                  max_models = 10,
                  seed = 1)

# View the AutoML Leaderboard
lb <- aml@leaderboard
autoML_results <- as.data.frame(lb) %>% select(model_id, rmse)

saveRDS(autoML_results, "autoML_results.RData")
print(autoML_result)
      
```

```{r}
# How long did the whole script take?
script_end <- Sys.time()

print(paste("Total script running time: ", round(difftime(script_end, script_start, units = "mins"), 1), " minutes"))
```

