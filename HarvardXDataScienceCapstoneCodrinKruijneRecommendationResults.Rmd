---
title: "Movie recommendation results"
output: html_notebook
---

# Loading packages and data

```{r}
# Load required packages
library(tidyverse)
library(lubridate)

# Load locally stored data
edx_original <- readRDS("edx.RData")
validation_original <- readRDS("validation.RData")
```

# Preparing data

```{r}
# Separating user characteristics, ratings and movie features
user_data <- edx_original %>% select(userId) %>% unique()
rating_data <- edx_original %>% select(userId, movieId, rating, timestamp)
movie_data <- edx_original %>% select(movieId, title, genres) %>% unique()

# Extract movie year from title
movie_data <- movie_data %>% mutate(movie_year = as.numeric(str_sub(title, -5, -2)))
# Let's make sure these are year numbers with exactly four digits
all(str_detect(movie_data$movie_year, "^\\d{4}$"))
# Remove year from title
movie_data <- movie_data %>% mutate(title = str_sub(title, 0, -8))
# Turn rating timestamps to date
rating_data <- rating_data %>% mutate(date = as.POSIXct(timestamp, origin = "1970-01-01"))
# Let's determine which genres we have
unique_genres <- unique(str_extract(movie_data$genres, "[^\\|]+"))
# Now lets add them as columns
movie_data[, unique_genres] <- NA
# For each of the ratings we detect present genres
for(g in 1:length(unique_genres)) {
  #print(paste("Detecting: ", unique_genres[g]))
  movie_data[, unique_genres[g]] <- str_detect(movie_data$genres, unique_genres[g])
}
# Drop old columns
movie_data <- movie_data %>% select(-genres)
rating_data <- rating_data %>% select(-timestamp)

# Let's explore our new data sets
head(user_data)
head(rating_data)
head(movie_data)
```

# User characteristics

```{r}
## Amount of ratings
user_ratings <- rating_data %>% add_count(userId, name = "user_ratings") %>%
                                select(userId, user_ratings) %>% unique()
user_data <- user_data %>% inner_join(user_ratings)

## Ratings statistics
user_stats <- rating_data %>% group_by(userId) %>%
                                summarise(user_median = median(rating),
                                          user_mean = mean(rating),
                                          user_sd = sd(rating)) %>%
                                select(userId, user_median, user_mean, user_sd) %>%
                                unique()
user_data <- user_data %>% inner_join(user_stats)
user_data$userId <- as.factor(user_data$userId)
```

# Movie characteristics

```{r}
# Number of ratings per movie
movie_ratings <- rating_data %>% add_count(movieId, name = "movie_ratings") %>%
                                 select(movieId, movie_ratings) %>% unique()
movie_data <- movie_data %>% inner_join(movie_ratings)

# Movie rating statistics
movie_stats <- rating_data %>% group_by(movieId) %>%
                               summarise(movie_median = median(rating),
                                         movie_mean = mean(rating),
                                         movie_sd = sd(rating)) %>%
                               select(movieId, movie_median, movie_mean, movie_sd) %>%
                               unique()

movie_data <- movie_data %>% inner_join(movie_stats)
movie_data$movieId <- as.factor(movie_data$movieId)
```

# Rating characteristics

```{r}

### CALCULATION OF rating_mean_diff should be inversed, but does not make sense to me ... ###

## Ratings - rating_mean
rating_mean <- mean(rating_data$rating)
rating_data <- rating_data %>% mutate(rating_mean_diff = rating - rating_mean)
rating_data <- rating_data %>% inner_join(movie_data[, c("movieId", "movie_mean")]) %>%
                               mutate(movie_mean_diff = rating - movie_mean)
rating_data$userId <- as.factor(rating_data$userId)
rating_data$movieId <- as.factor(rating_data$movieId)

# Let's simplify the rating date to year
rating_data$rating_year <- year(rating_data$date)
rating_data$date <- NULL
```

# Model training preparation
```{r}
library(caret)

# RSME loss function function to evaluate models
RMSE <- function(true_ratings, predicted_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}

# Create train and test sets
test_index <- createDataPartition(y = rating_data$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- rating_data[-test_index,]
test_set <- rating_data[test_index,]

# To make sure movies and users are in both train and test sets
test_set <- test_set %>% 
     semi_join(train_set, by = "movieId") %>%
     semi_join(train_set, by = "userId")

```

# Model building

```{r}
### Building the Recommendation System

# Naive model using average rating
rating_mean <- mean(train_set$rating)
rating_mean

naive_rmse <- RMSE(test_set$rating, rating_mean)

rmse_results <- data_frame(method = "Average rating", RMSE = naive_rmse)

# Model using fixed number
fixed_number <- rep(2.5, nrow(test_set))

fixed_rmse <- RMSE(test_set$rating, fixed_number)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Fixed number 2.5",
                                     RMSE = fixed_rmse ))

rmse_results
```

# Model tweaking

```{r}
# Taking into consideration rating effect; calculing the average per movie of the difference between each rating and the average overall rating
rating_effect_training <- train_set %>% group_by(movieId) %>%
                                           summarise(rating_mean_diff_avg = rating_mean - mean(rating_mean_diff))

# Apply predictions to the test set
rating_effect_predictions <- test_set %>% inner_join(rating_effect_training)

# Using the difference between movie mean and user rating

rating_effect_rmse <- RMSE(test_set$rating, rating_effect_predictions$rating_mean_diff_avg)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Rating effect",
                                     RMSE = rating_effect_rmse ))

# Taking into consideration movie effect; calculing the average per movie of the difference between each rating and the movie average rating
movie_effect_training <- train_set %>% group_by(movieId) %>%
                                       summarise(movie_mean_diff_avg = mean(movie_mean_diff))

# Apply predictions to the test set
movie_effect_predictions <- test_set %>% inner_join(movie_effect_training)

# Using the difference between movie mean and user rating

movie_effect_rmse <- RMSE(test_set$rating, movie_effect_predictions$movie_mean_diff_avg)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method="Movie effect",
                                     RMSE = movie_effect_rmse ))

rmse_results

## Something's off with my thinking here ;-)

```

```{r}

# Let's merged derived data

train_set_plus <- train_set %>% left_join(user_data, by = "userId") %>%
                                left_join(movie_data, by = "movieId")
train_set_plus$userId <- as.factor(train_set_plus$userId)
train_set_plus$movieId <- as.factor(train_set_plus$movieId)
train_set_plus$movie_year <- as.factor(train_set_plus$movie_year)

# Create test_set_plus
test_set_plus <- test_set %>% left_join(user_data, by = "userId") %>%
                              left_join(movie_data, by = "movieId")
test_set_plus$userId <- as.factor(test_set_plus$userId)
test_set_plus$movieId <- as.factor(test_set_plus$movieId)
test_set_plus$movie_year <- as.factor(test_set_plus$movie_year)
```

# Train mode models
```{r}

# Let's prepare parallel processing
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

## Model training in parallel

tc <- trainControl(number = 10)

system.time({
  model_1 <- train(rating ~ movieId,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_1$finalModel

system.time({
  model_2 <- train(rating ~ movieId + userId,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_2$finalModel

system.time({
  model_3 <- train(rating ~ movieId + userId + movie_mean.x,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_3$finalModel

## Does it matter what the movies are? Maybe focus on the ratings

system.time({
  model_4 <- train(rating ~ movie_mean.x,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_4$finalModel

system.time({
  model_5 <- train(rating ~ movie_mean.x + user_mean,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_5$finalModel

system.time({
  model_6 <- train(rating ~ movie_mean.x + movie_sd + user_mean + user_sd,
                   data = train_set_plus, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_6$finalModel

# Lets add some more characteristics

## Stopping clusters
stopCluster(cl)

```

# Prediction and results
```{r}

# Predict on test_set
model_1_predictions <- predict(model_1, newdata = test_set_plus)
model_2_predictions <- predict(model_2, newdata = test_set_plus)
model_3_predictions <- predict(model_3, newdata = test_set_plus)
model_4_predictions <- predict(model_4, newdata = test_set_plus)
model_5_predictions <- predict(model_5, newdata = test_set_plus)
model_6_predictions <- predict(model_6, newdata = test_set_plus)

# Print results on test set

print(paste("Model 1 RMSE in test set: ", RMSE(test_set_plus$rating, model_1_predictions)))
print(paste("Model 2 RMSE in test set: ", RMSE(test_set_plus$rating, model_2_predictions)))
print(paste("Model 3 RMSE in test set: ", RMSE(test_set_plus$rating, model_3_predictions)))
print(paste("Model 4 RMSE in test set: ", RMSE(test_set_plus$rating, model_4_predictions)))
print(paste("Model 5 RMSE in test set: ", RMSE(test_set_plus$rating, model_5_predictions)))
print(paste("Model 6 RMSE in test set: ", RMSE(test_set_plus$rating, model_6_predictions)))

# Verify results on validation set


  
```

