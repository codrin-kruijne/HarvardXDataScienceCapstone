---
title: "Movie recommendation results"
output:
  pdf_document: default
  html_notebook: default
---

# Loading packages and data

```{r}
# Load required packages
library(tidyverse)
library(lubridate)

# Load locally stored data
edx_original <- readRDS("edx.RData")
validation_original <- readRDS("validation.RData")
```

# Preparing data

```{r}
# Separating user characteristics, ratings and movie features
user_data <- edx_original %>% select(userId) %>%
                              mutate(userId = as.factor(userId)) %>% unique()

rating_data <- edx_original %>% select(userId, movieId, rating, timestamp) %>%
                                mutate(userId = as.factor(userId),
                                       movieId = as.factor(movieId),
                                       date = as.POSIXct(timestamp, origin = "1970-01-01")) %>% # Turn rating timestamps to date
                                mutate(rating_year = year(date)) %>%
                                select(-timestamp, -date)

# MOVIE DATA
movie_data <- edx_original %>% select(movieId, title, genres) %>%
                               unique() %>%
                               mutate(movieId = as.factor(movieId),
                                      movie_year = as.factor(str_sub(title, -5, -2)),
                                      title = str_sub(title, 0, -8))

# Let's determine which genres we have
unique_genres <- unique(str_extract(movie_data$genres, "[^\\|]+"))
# Now lets add them as columns
movie_data[, unique_genres] <- NA
# For each of the ratings we detect present genres
for(g in 1:length(unique_genres)) {
  #print(paste("Detecting: ", unique_genres[g]))
  movie_data[, unique_genres[g]] <- str_detect(movie_data$genres, unique_genres[g])
}
# Drop old columns
movie_data <- movie_data %>% select(-genres)

# Let's explore our new data sets
head(user_data)
head(rating_data)
head(movie_data)
```

# User characteristics

```{r}
## Ratings statistics
user_stats <- rating_data %>% group_by(userId) %>%
                                summarise(user_ratings = n(),
                                          user_median = median(rating),
                                          user_mean = mean(rating),
                                          user_sd = sd(rating)) %>%
                                select(userId, user_median, user_mean, user_sd) %>%
                                unique()

user_data <- user_data %>% inner_join(user_stats, by = "userId")


## TO DO: ADD GENRE AVERAGES
```

# Movie characteristics

```{r}

# Movie rating statistics
movie_stats <- rating_data %>% group_by(movieId) %>%
                               summarise(movie_ratings = n(),
                                         movie_median = median(rating),
                                         movie_mean = mean(rating),
                                         movie_sd = sd(rating)) %>%
                               select(movieId, movie_median, movie_mean, movie_sd) %>%
                               unique()

movie_data <- movie_data %>% inner_join(movie_stats, by = "movieId")

```

# Rating characteristics

```{r}

## Rating characteristics
rating_mean <- mean(rating_data$rating)

rating_data <- rating_data %>% mutate(rating_mean_diff = rating - rating_mean) %>%
                               inner_join(movie_data[, c("movieId", "movie_mean")], by = "movieId") %>%
                               mutate(movie_mean_diff = rating - movie_mean) %>% 
                               inner_join(user_data[, c("userId", "user_mean")], by = "userId") %>%
                               mutate(user_mean_diff = rating - user_mean)


```

# Model training preparation
```{r}
library(caret)

# RSME loss function function to evaluate models
RMSE <- function(true_ratings, predicted_ratings){
     sqrt(mean((true_ratings - predicted_ratings)^2))
}

# Create train and test sets
test_index <- createDataPartition(y = rating_data$rating, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- rating_data[-test_index,]
test_set <- rating_data[test_index,]

# To make sure movies and users are in both train and test sets
test_set <- test_set %>% 
     semi_join(train_set, by = "movieId") %>%
     semi_join(train_set, by = "userId")

```

# Manual model building

```{r}
### Building the Recommendation System

# Naive model using average rating
rating_mean <- mean(train_set$rating)
rating_mean

naive_rmse <- RMSE(test_set$rating, rating_mean)

rmse_results <- data_frame(method = "Average rating", RMSE = naive_rmse)

# Model using fixed number
fixed_number <- rep(2.5, nrow(test_set))

fixed_rmse <- RMSE(test_set$rating, fixed_number)

rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "Fixed number 2.5",
                                     RMSE = fixed_rmse ))

rmse_results
```

# Derived models

```{r}

# Derived predictions

predictions <- test_set %>% group_by(movieId) %>%
               # Rating effect (effect of rating scale used; looking at differences from rating mean)      
               summarise(rating_mean_diff_avg = rating_mean + mean(rating_mean_diff),
               # Movie effect (effect of general movie popularity; looking at differences between user rating and movie mean)
                         movie_mean_diff_avg = rating_mean + mean(movie_mean_diff),
               # User effect (effect of user rating behaviour; looking at differeces between rating and average user rating)
                         user_mean_diff_avg = rating_mean + mean(user_mean_diff),
               # User-movie effect (effect of user rating behaviour; looking at differeces between user rating and average movie rating)
                         user_movie_mean_diff_avg = mean(movie_mean) + mean(user_mean_diff))

# Calculate RMSEs

rating_effect_rmse <- RMSE(test_set$rating,
                           predictions$rating_mean_diff_avg)
movie_effect_rmse <- RMSE(test_set$rating,
                          predictions$movie_mean_diff_avg)
user_effect_rmse <- RMSE(test_set$rating,
                         predictions$user_mean_diff_avg)
user_movie_effect_rmse <- RMSE(test_set$rating,
                               predictions$user_movie_mean_diff_avg)

# Print RMSEs

rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "Rating effect",
                                     RMSE = rating_effect_rmse))
rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "Movie effect",
                                     RMSE = movie_effect_rmse))
rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "User effect",
                                     RMSE = user_effect_rmse))
rmse_results <- bind_rows(rmse_results,
                          data_frame(method = "User-movie effect",
                                     RMSE = user_movie_effect_rmse))
rmse_results

```


# Merge all data for calculating models
```{r}

# Let's merged derived data
train_set_plus <- train_set %>% select(-user_mean) %>%
                                left_join(user_data, by = "userId") %>%
                                select(-movie_mean) %>%
                                left_join(movie_data, by = "movieId")

test_set_plus <- test_set %>% select(-user_mean) %>%
                                left_join(user_data, by = "userId") %>%
                                select(-movie_mean) %>%
                                left_join(movie_data, by = "movieId")

```


# Train calculated models
```{r}

# Let's prepare parallel processing
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

## Model training in parallel

tc <- trainControl(number = 3)
training_data <- train_set_plus[1:100000,]

system.time({
  model_1 <- train(rating ~ movie_median,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_1$finalModel

system.time({
  model_2 <- train(rating ~ movie_median + movie_mean,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_2$finalModel

system.time({
  model_3 <- train(rating ~ movie_median + movie_mean + movie_sd,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_3$finalModel

## Does it matter what the movies are? Maybe focus on the ratings

system.time({
  model_4 <- train(rating ~ user_median,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_4$finalModel

system.time({
  model_5 <- train(rating ~ user_median + user_mean,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_5$finalModel

system.time({
  model_6 <- train(rating ~ user_median + user_mean + user_sd,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_6$finalModel

# User and movie effects combined

system.time({
  model_7 <- train(rating ~ movie_median + user_median,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_7$finalModel

system.time({
  model_8 <- train(rating ~ movie_median + movie_mean + user_median + user_mean,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_8$finalModel

system.time({
  model_9 <- train(rating ~ movie_median + movie_mean + movie_sd + user_median + user_mean + user_sd,
                   data = training_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_9$finalModel

# Basic movie_mean and user_mean seem most influential
final_model_data <- train_set_plus %>% select(movieId, rating, movie_mean, user_mean) %>% unique()
system.time({
  model_10 <- train(rating ~ movie_mean + user_mean,
                   data = final_model_data, method = "lm", 
                   na.action = na.omit, metric = "RMSE",
                   trainControl = tc)
})
model_10$finalModel

## Stopping clusters
stopCluster(cl)

```

# Prediction and results
```{r}

# Predict on test_set
model_1_predictions <- predict(model_1, newdata = test_set_plus)
model_2_predictions <- predict(model_2, newdata = test_set_plus)
model_3_predictions <- predict(model_3, newdata = test_set_plus)
model_4_predictions <- predict(model_4, newdata = test_set_plus)
model_5_predictions <- predict(model_5, newdata = test_set_plus)
model_6_predictions <- predict(model_6, newdata = test_set_plus)
model_7_predictions <- predict(model_7, newdata = test_set_plus)
model_8_predictions <- predict(model_8, newdata = test_set_plus)
model_9_predictions <- predict(model_9, newdata = test_set_plus)
model_10_predictions <- predict(model_10, newdata = test_set_plus)

# Print results on test set

print(paste("Model 1 RMSE in test set: ", RMSE(test_set_plus$rating, model_1_predictions)))
print(paste("Model 2 RMSE in test set: ", RMSE(test_set_plus$rating, model_2_predictions)))
print(paste("Model 3 RMSE in test set: ", RMSE(test_set_plus$rating, model_3_predictions)))
print(paste("Model 4 RMSE in test set: ", RMSE(test_set_plus$rating, model_4_predictions)))
print(paste("Model 5 RMSE in test set: ", RMSE(test_set_plus$rating, model_5_predictions)))
print(paste("Model 6 RMSE in test set: ", RMSE(test_set_plus$rating, model_6_predictions)))
print(paste("Model 7 RMSE in test set: ", RMSE(test_set_plus$rating, model_7_predictions)))
print(paste("Model 8 RMSE in test set: ", RMSE(test_set_plus$rating, model_8_predictions)))
print(paste("Model 9 RMSE in test set: ", RMSE(test_set_plus$rating, model_9_predictions)))
print(paste("Model 10 RMSE in test set: ", RMSE(test_set_plus$rating, model_10_predictions)))

# Verify results on validation set


  
```

```{r}

# Shall we explore auto ML?

library(h2o)

h2o.init()

# Import a sample binary outcome train/test set into H2O
train <- as.h2o(train_set_plus)
test <- as.h2o(test_set_plus)

# Identify predictors and response
y <- "rating"
x <- setdiff(names(train_set_plus), y)

# Run AutoML for 10 base models (limited to 1 hour max runtime by default)
aml <- h2o.automl(x = x, y = y,
                  training_frame = train,
                  max_models = 10,
                  seed = 1)

# View the AutoML Leaderboard
lb <- aml@leaderboard
print(lb, n = nrow(lb))
      
```

